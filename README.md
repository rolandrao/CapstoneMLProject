# CapstoneMLProject

## Overview
### Business Understanding
The purpose of this project is to generate the ability to detect sign language gestures from still images and translate/transcribe them
into an understandable format for the public using AI/ML techniques. This tool would be applicable to multiple domains, including business 
and education industries. The motivation lies behind the general lack of resources in todayâ€™s world regarding the translation of sign 
language and the potential behind using AI to automate such an issue.

## Data Science Steps Taken
1) Define and understand a business problem <br>
2) Find the necessary data to be used <br>
3) Perform necessary cleaning operations and transformations to make data useable <br>
4) Produce models and analyze results based off needs <br>
5) Determine future steps to maximize accuracy further <br>

## Packages Used
### Standard Packages
pandas <br>
numpy <br>
matplotlib.pyplot <br>
seaborn <br>
### Sklearn Packages
sklearn.metrics <br>
sklearn.preprocessing <br>
### Keras and Tensorflow Packages
keras.utils.np_utils <br>
keras.models <br>
keras.layers <br>
keras.preprocessing.image <br>
keras.callbacks <br>
tensorflow.keras.optimizers <br>

## Navigating Instructions
The main deliverables for this project are located in the Exploratory Data Analysis notebook. To access the data used for this project click on the data folder and then the zipped data folder, all of the data provided for this project is located in this folder. 
